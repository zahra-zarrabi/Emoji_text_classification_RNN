{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1VuBNV_wAHk3QnH4sZy1-3b1qvqN67zJF",
      "authorship_tag": "ABX9TyN6euTBHFF22hbeIVvpovLb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahra-zarrabi/Emoji_text_classification_RNN/blob/main/EmojiFier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import required packages"
      ],
      "metadata": {
        "id": "sO59BD_LJJ-l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GVmuTi8VaRzL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM ,GRU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "JkPW00UniReF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f2e478-b6e5-461a-8ec8-6882151b799c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset EMOJISET\n",
        "Tiny dataset (X, Y) where:\n",
        "- X contains 132 sentences (strings)\n",
        "- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence\n",
        "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/data_set.png?raw=1\\\" \n",
        "style=\"width:700px;height:300px;\">\n"
      ],
      "metadata": {
        "id": "BVMjrSzzpVOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(filename):\n",
        "  data_frame = pd.read_csv(filename)\n",
        "  X = np.asarray(data_frame['sentence'])\n",
        "  Y = np.asarray(data_frame['label'], dtype=int)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "ah8ZJCd3ezfp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = read_csv('/content/drive/MyDrive/Emoji_Text_Classification/train.csv')\n",
        "X_test, Y_test = read_csv('/content/drive/MyDrive/Emoji_Text_Classification/test.csv')"
      ],
      "metadata": {
        "id": "CdyVZpdugmOx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_emoji(label):\n",
        "  emojies=[\"‚ù§Ô∏è\",'‚öΩ','üòÇ','üòî','üçΩÔ∏è']\n",
        "  return emojies[label]"
      ],
      "metadata": {
        "id": "NwpZvMRjjOs1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[3],label_to_emoji(Y_train[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mn7avRDsmLz6",
        "outputId": "6029fecb-5966-4485-846f-bf21ccff5d30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Miss you so much', '‚ù§Ô∏è')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the largest sentence by word count\n",
        "max_len = len(max(X_train,key=len).split())\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3HVbCPHnFll",
        "outputId": "e709cea9-d8e7-4538-b706-2d7879d94bda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert labels to one hot\n",
        "Y_train_oh = tf.keras.utils.to_categorical(Y_train, 5)\n",
        "Y_test_oh = tf.keras.utils.to_categorical(Y_test, 5)"
      ],
      "metadata": {
        "id": "B3McpBO-abzP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[3],Y_train_oh[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1HYH2sAhjsa",
        "outputId": "f2eecb79-5436-4d0f-cc8f-34773a5efe79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Miss you so much', array([1., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read feature vectors and save them\n",
        "# the word comes first, and then the feature vectors(each word is in one line)\n",
        "def read_glove_vectors(glove_file):\n",
        "  f = open(glove_file , encoding = 'utf8')\n",
        "  words = set()\n",
        "  words_to_vec = dict()\n",
        "  for line in f:\n",
        "    line = line.strip().split()\n",
        "    word = line[0]\n",
        "    vec = line[1:]\n",
        "    words.add(word)\n",
        "    words_to_vec[word] = np.array(vec, dtype=np.float64)\n",
        "  return words_to_vec"
      ],
      "metadata": {
        "id": "wxEKZM4Zddt2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract glove.6B for feature vectors \n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip -d glov.6B"
      ],
      "metadata": {
        "id": "VcY7e8JUabxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_vec = read_glove_vectors('/content/drive/MyDrive/glove/glove.6B.50d.txt')"
      ],
      "metadata": {
        "id": "tQhob8rHhN2y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_to_vec['flower']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SY_mX1pijLl",
        "outputId": "4a931976-1ade-4a7d-fd21-d4cf1a248454"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.075439 ,  1.2659   , -1.3179   ,  0.11341  ,  1.4513   ,\n",
              "        0.17337  , -0.56265  , -1.0706   ,  0.54898  ,  0.30163  ,\n",
              "       -0.11471  ,  0.38498  ,  0.9205   , -0.2491   ,  0.3308   ,\n",
              "        0.060113 , -0.0068846,  0.086864 , -0.20535  , -0.86098  ,\n",
              "        0.10007  , -0.75486  ,  0.48225  , -0.33253  , -0.23791  ,\n",
              "        0.17345  ,  0.49777  ,  0.88761  ,  0.089471 , -0.56217  ,\n",
              "        1.8535   , -0.0055493,  0.45845  ,  0.53943  ,  0.3247   ,\n",
              "        0.43479  , -0.027253 ,  0.44744  , -0.27514  , -0.016152 ,\n",
              "       -0.51024  , -0.10113  , -0.80985  , -0.31571  ,  1.5817   ,\n",
              "        0.2105   , -0.1844   , -1.7266   ,  0.092685 , -0.55696  ])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emojifier_V1\n",
        "Each word has some feature, and in Emojifier-V1 we want to classify sentences using multilayer perceptron:\n",
        "- We get the average of words in each sentence and then forward it to the multilayer perceptron with 50 input neurons(each word has 50 features, then the average of words in the sentence has 50 features) and an output layer of softmax with 5 neurons.\n",
        "- For feature vectors, we can get from this link: http://nlp.stanford.edu/data/glove.6B.zip\",\n",
        "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/image_1.png?raw=1\\\" style=\"width:900px;height:300px;\\\">\n"
      ],
      "metadata": {
        "id": "FBBpjxs-a0Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Convert sentences to the average of the word vectors\n",
        "def sentence_to_avg(sentence):\n",
        "  words = sentence.lower().split()\n",
        "  sum_vectors = np.zeros((50,))\n",
        "  for w in words:\n",
        "    sum_vectors += words_to_vec[w]\n",
        "  avg_vectors = sum_vectors / len(words)\n",
        "  return avg_vectors"
      ],
      "metadata": {
        "id": "Jkx1RjG_jpMh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average of all sentences\n",
        "X_train_avg = []\n",
        "for i in range(X_train.shape[0]):\n",
        "  X_train_avg.append(sentence_to_avg(X_train[i]))\n",
        "X_train_avg = np.array(X_train_avg) "
      ],
      "metadata": {
        "id": "-keiG-PdnNB3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_avg.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vZepY47nM_Z",
        "outputId": "c356ba1f-b9c7-4a8b-d37f-f27f59a6bc2d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Emoji_Net_V1(Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense = Dense(5, input_shape=(50,), activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.dense(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "ni7lJUh_sOwe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v1 = Emoji_Net_V1()"
      ],
      "metadata": {
        "id": "42hB9ZZ5uAWz"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v1.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "TU7sZ6touK-0"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v1.fit(X_train_avg, Y_train_oh, epochs=400, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0uOQbrjuT8D",
        "outputId": "52a584df-7dc8-4280-861b-7a759f41eda3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.8197 - accuracy: 0.1818\n",
            "Epoch 2/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7716 - accuracy: 0.1894\n",
            "Epoch 3/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.7317 - accuracy: 0.2045\n",
            "Epoch 4/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6958 - accuracy: 0.2424\n",
            "Epoch 5/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.6651 - accuracy: 0.2576\n",
            "Epoch 6/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.6380 - accuracy: 0.2955\n",
            "Epoch 7/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.6127 - accuracy: 0.2803\n",
            "Epoch 8/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5909 - accuracy: 0.3106\n",
            "Epoch 9/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5724 - accuracy: 0.3258\n",
            "Epoch 10/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5553 - accuracy: 0.3106\n",
            "Epoch 11/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5403 - accuracy: 0.3258\n",
            "Epoch 12/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.5262 - accuracy: 0.3409\n",
            "Epoch 13/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5140 - accuracy: 0.3561\n",
            "Epoch 14/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.5020 - accuracy: 0.3636\n",
            "Epoch 15/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4911 - accuracy: 0.3485\n",
            "Epoch 16/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4813 - accuracy: 0.3712\n",
            "Epoch 17/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4714 - accuracy: 0.3864\n",
            "Epoch 18/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4621 - accuracy: 0.3636\n",
            "Epoch 19/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4539 - accuracy: 0.3788\n",
            "Epoch 20/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4451 - accuracy: 0.3788\n",
            "Epoch 21/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4363 - accuracy: 0.3788\n",
            "Epoch 22/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4281 - accuracy: 0.3788\n",
            "Epoch 23/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4199 - accuracy: 0.3864\n",
            "Epoch 24/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.4115 - accuracy: 0.3788\n",
            "Epoch 25/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.4031 - accuracy: 0.3788\n",
            "Epoch 26/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3949 - accuracy: 0.3939\n",
            "Epoch 27/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3873 - accuracy: 0.4091\n",
            "Epoch 28/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3800 - accuracy: 0.4242\n",
            "Epoch 29/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3741 - accuracy: 0.4167\n",
            "Epoch 30/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3669 - accuracy: 0.4242\n",
            "Epoch 31/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3590 - accuracy: 0.4242\n",
            "Epoch 32/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3518 - accuracy: 0.4318\n",
            "Epoch 33/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3442 - accuracy: 0.4394\n",
            "Epoch 34/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3368 - accuracy: 0.4470\n",
            "Epoch 35/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3305 - accuracy: 0.4394\n",
            "Epoch 36/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3237 - accuracy: 0.4394\n",
            "Epoch 37/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.3171 - accuracy: 0.4545\n",
            "Epoch 38/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3113 - accuracy: 0.4621\n",
            "Epoch 39/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.3045 - accuracy: 0.4621\n",
            "Epoch 40/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2983 - accuracy: 0.4621\n",
            "Epoch 41/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2921 - accuracy: 0.4621\n",
            "Epoch 42/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2856 - accuracy: 0.4773\n",
            "Epoch 43/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2802 - accuracy: 0.4924\n",
            "Epoch 44/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2733 - accuracy: 0.5000\n",
            "Epoch 45/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2671 - accuracy: 0.5076\n",
            "Epoch 46/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2622 - accuracy: 0.5227\n",
            "Epoch 47/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2556 - accuracy: 0.5152\n",
            "Epoch 48/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2492 - accuracy: 0.5152\n",
            "Epoch 49/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2425 - accuracy: 0.5076\n",
            "Epoch 50/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2374 - accuracy: 0.5076\n",
            "Epoch 51/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2308 - accuracy: 0.5227\n",
            "Epoch 52/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.2248 - accuracy: 0.5227\n",
            "Epoch 53/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2194 - accuracy: 0.5303\n",
            "Epoch 54/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2139 - accuracy: 0.5303\n",
            "Epoch 55/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2084 - accuracy: 0.5379\n",
            "Epoch 56/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.2029 - accuracy: 0.5455\n",
            "Epoch 57/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.1980 - accuracy: 0.5530\n",
            "Epoch 58/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1926 - accuracy: 0.5530\n",
            "Epoch 59/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1879 - accuracy: 0.5455\n",
            "Epoch 60/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1822 - accuracy: 0.5455\n",
            "Epoch 61/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1770 - accuracy: 0.5455\n",
            "Epoch 62/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1715 - accuracy: 0.5455\n",
            "Epoch 63/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1668 - accuracy: 0.5455\n",
            "Epoch 64/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1614 - accuracy: 0.5606\n",
            "Epoch 65/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1567 - accuracy: 0.5606\n",
            "Epoch 66/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1524 - accuracy: 0.5606\n",
            "Epoch 67/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1475 - accuracy: 0.5682\n",
            "Epoch 68/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1427 - accuracy: 0.5682\n",
            "Epoch 69/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1384 - accuracy: 0.5758\n",
            "Epoch 70/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1343 - accuracy: 0.5833\n",
            "Epoch 71/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1305 - accuracy: 0.5833\n",
            "Epoch 72/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1263 - accuracy: 0.5606\n",
            "Epoch 73/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1221 - accuracy: 0.5682\n",
            "Epoch 74/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1178 - accuracy: 0.5833\n",
            "Epoch 75/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1134 - accuracy: 0.5833\n",
            "Epoch 76/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.1092 - accuracy: 0.5833\n",
            "Epoch 77/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.5758\n",
            "Epoch 78/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.1017 - accuracy: 0.5909\n",
            "Epoch 79/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0979 - accuracy: 0.5985\n",
            "Epoch 80/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0935 - accuracy: 0.5985\n",
            "Epoch 81/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0888 - accuracy: 0.5985\n",
            "Epoch 82/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0840 - accuracy: 0.5909\n",
            "Epoch 83/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0805 - accuracy: 0.5758\n",
            "Epoch 84/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.0766 - accuracy: 0.5909\n",
            "Epoch 85/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0728 - accuracy: 0.6061\n",
            "Epoch 86/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0683 - accuracy: 0.6061\n",
            "Epoch 87/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0638 - accuracy: 0.6061\n",
            "Epoch 88/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0599 - accuracy: 0.5985\n",
            "Epoch 89/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0557 - accuracy: 0.6212\n",
            "Epoch 90/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0522 - accuracy: 0.6364\n",
            "Epoch 91/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0490 - accuracy: 0.6364\n",
            "Epoch 92/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0454 - accuracy: 0.6364\n",
            "Epoch 93/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0416 - accuracy: 0.6439\n",
            "Epoch 94/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0379 - accuracy: 0.6515\n",
            "Epoch 95/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0344 - accuracy: 0.6591\n",
            "Epoch 96/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0319 - accuracy: 0.6591\n",
            "Epoch 97/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0282 - accuracy: 0.6667\n",
            "Epoch 98/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0248 - accuracy: 0.6667\n",
            "Epoch 99/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1.0210 - accuracy: 0.6667\n",
            "Epoch 100/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0178 - accuracy: 0.6515\n",
            "Epoch 101/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0142 - accuracy: 0.6515\n",
            "Epoch 102/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0099 - accuracy: 0.6515\n",
            "Epoch 103/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0064 - accuracy: 0.6591\n",
            "Epoch 104/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 1.0032 - accuracy: 0.6742\n",
            "Epoch 105/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 1.0007 - accuracy: 0.6742\n",
            "Epoch 106/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9972 - accuracy: 0.6742\n",
            "Epoch 107/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9934 - accuracy: 0.6742\n",
            "Epoch 108/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9899 - accuracy: 0.6818\n",
            "Epoch 109/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.9863 - accuracy: 0.6970\n",
            "Epoch 110/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9831 - accuracy: 0.7121\n",
            "Epoch 111/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9801 - accuracy: 0.7121\n",
            "Epoch 112/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9772 - accuracy: 0.7121\n",
            "Epoch 113/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9735 - accuracy: 0.7121\n",
            "Epoch 114/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9705 - accuracy: 0.7197\n",
            "Epoch 115/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9675 - accuracy: 0.7121\n",
            "Epoch 116/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9640 - accuracy: 0.7197\n",
            "Epoch 117/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9606 - accuracy: 0.7273\n",
            "Epoch 118/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9579 - accuracy: 0.7273\n",
            "Epoch 119/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9546 - accuracy: 0.7197\n",
            "Epoch 120/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9518 - accuracy: 0.7121\n",
            "Epoch 121/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9494 - accuracy: 0.7121\n",
            "Epoch 122/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9460 - accuracy: 0.7121\n",
            "Epoch 123/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9434 - accuracy: 0.7045\n",
            "Epoch 124/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9403 - accuracy: 0.7045\n",
            "Epoch 125/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9375 - accuracy: 0.7045\n",
            "Epoch 126/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9343 - accuracy: 0.7121\n",
            "Epoch 127/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9316 - accuracy: 0.7121\n",
            "Epoch 128/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9287 - accuracy: 0.7197\n",
            "Epoch 129/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9264 - accuracy: 0.7348\n",
            "Epoch 130/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9238 - accuracy: 0.7500\n",
            "Epoch 131/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9214 - accuracy: 0.7500\n",
            "Epoch 132/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9189 - accuracy: 0.7576\n",
            "Epoch 133/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9159 - accuracy: 0.7500\n",
            "Epoch 134/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9135 - accuracy: 0.7576\n",
            "Epoch 135/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.9107 - accuracy: 0.7500\n",
            "Epoch 136/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9082 - accuracy: 0.7500\n",
            "Epoch 137/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9057 - accuracy: 0.7576\n",
            "Epoch 138/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9031 - accuracy: 0.7576\n",
            "Epoch 139/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.9010 - accuracy: 0.7576\n",
            "Epoch 140/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8990 - accuracy: 0.7576\n",
            "Epoch 141/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8959 - accuracy: 0.7576\n",
            "Epoch 142/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8930 - accuracy: 0.7500\n",
            "Epoch 143/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8907 - accuracy: 0.7576\n",
            "Epoch 144/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8884 - accuracy: 0.7652\n",
            "Epoch 145/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8859 - accuracy: 0.7652\n",
            "Epoch 146/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8835 - accuracy: 0.7652\n",
            "Epoch 147/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8810 - accuracy: 0.7500\n",
            "Epoch 148/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8784 - accuracy: 0.7424\n",
            "Epoch 149/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8761 - accuracy: 0.7424\n",
            "Epoch 150/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8740 - accuracy: 0.7500\n",
            "Epoch 151/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8718 - accuracy: 0.7500\n",
            "Epoch 152/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8699 - accuracy: 0.7500\n",
            "Epoch 153/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8677 - accuracy: 0.7500\n",
            "Epoch 154/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8653 - accuracy: 0.7500\n",
            "Epoch 155/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8633 - accuracy: 0.7500\n",
            "Epoch 156/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8610 - accuracy: 0.7500\n",
            "Epoch 157/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8589 - accuracy: 0.7576\n",
            "Epoch 158/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8567 - accuracy: 0.7652\n",
            "Epoch 159/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.8545 - accuracy: 0.7652\n",
            "Epoch 160/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8525 - accuracy: 0.7727\n",
            "Epoch 161/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8505 - accuracy: 0.7727\n",
            "Epoch 162/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8484 - accuracy: 0.7803\n",
            "Epoch 163/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8460 - accuracy: 0.7727\n",
            "Epoch 164/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8439 - accuracy: 0.7727\n",
            "Epoch 165/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8418 - accuracy: 0.7727\n",
            "Epoch 166/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8398 - accuracy: 0.7727\n",
            "Epoch 167/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8381 - accuracy: 0.7652\n",
            "Epoch 168/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8361 - accuracy: 0.7652\n",
            "Epoch 169/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8345 - accuracy: 0.7727\n",
            "Epoch 170/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8324 - accuracy: 0.7652\n",
            "Epoch 171/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8306 - accuracy: 0.7727\n",
            "Epoch 172/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8289 - accuracy: 0.7727\n",
            "Epoch 173/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8268 - accuracy: 0.7803\n",
            "Epoch 174/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8245 - accuracy: 0.7879\n",
            "Epoch 175/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8225 - accuracy: 0.7879\n",
            "Epoch 176/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8203 - accuracy: 0.7803\n",
            "Epoch 177/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8184 - accuracy: 0.7803\n",
            "Epoch 178/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8163 - accuracy: 0.7803\n",
            "Epoch 179/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.8148 - accuracy: 0.7803\n",
            "Epoch 180/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8125 - accuracy: 0.7803\n",
            "Epoch 181/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8103 - accuracy: 0.7803\n",
            "Epoch 182/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.8089 - accuracy: 0.7727\n",
            "Epoch 183/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8065 - accuracy: 0.7727\n",
            "Epoch 184/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8046 - accuracy: 0.7803\n",
            "Epoch 185/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8028 - accuracy: 0.7955\n",
            "Epoch 186/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.8013 - accuracy: 0.7879\n",
            "Epoch 187/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7994 - accuracy: 0.7879\n",
            "Epoch 188/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7976 - accuracy: 0.7879\n",
            "Epoch 189/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7959 - accuracy: 0.7955\n",
            "Epoch 190/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7942 - accuracy: 0.7955\n",
            "Epoch 191/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.7879\n",
            "Epoch 192/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7903 - accuracy: 0.7879\n",
            "Epoch 193/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7888 - accuracy: 0.7955\n",
            "Epoch 194/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7867 - accuracy: 0.7955\n",
            "Epoch 195/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7848 - accuracy: 0.7955\n",
            "Epoch 196/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7841 - accuracy: 0.7955\n",
            "Epoch 197/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7822 - accuracy: 0.7955\n",
            "Epoch 198/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7804 - accuracy: 0.7879\n",
            "Epoch 199/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7787 - accuracy: 0.7879\n",
            "Epoch 200/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7770 - accuracy: 0.7879\n",
            "Epoch 201/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.7803\n",
            "Epoch 202/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7742 - accuracy: 0.7879\n",
            "Epoch 203/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7724 - accuracy: 0.7955\n",
            "Epoch 204/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7702 - accuracy: 0.8030\n",
            "Epoch 205/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7688 - accuracy: 0.8030\n",
            "Epoch 206/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7670 - accuracy: 0.8030\n",
            "Epoch 207/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.7955\n",
            "Epoch 208/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.8030\n",
            "Epoch 209/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7628 - accuracy: 0.7955\n",
            "Epoch 210/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7612 - accuracy: 0.8030\n",
            "Epoch 211/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.8106\n",
            "Epoch 212/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7584 - accuracy: 0.8030\n",
            "Epoch 213/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7563 - accuracy: 0.8030\n",
            "Epoch 214/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7551 - accuracy: 0.8030\n",
            "Epoch 215/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7531 - accuracy: 0.8030\n",
            "Epoch 216/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7515 - accuracy: 0.8030\n",
            "Epoch 217/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7499 - accuracy: 0.7955\n",
            "Epoch 218/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7482 - accuracy: 0.7955\n",
            "Epoch 219/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.8030\n",
            "Epoch 220/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7444 - accuracy: 0.8030\n",
            "Epoch 221/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.8030\n",
            "Epoch 222/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7417 - accuracy: 0.7879\n",
            "Epoch 223/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7407 - accuracy: 0.7879\n",
            "Epoch 224/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7394 - accuracy: 0.7955\n",
            "Epoch 225/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.7388 - accuracy: 0.7955\n",
            "Epoch 226/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7371 - accuracy: 0.8030\n",
            "Epoch 227/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7356 - accuracy: 0.8030\n",
            "Epoch 228/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.8030\n",
            "Epoch 229/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7327 - accuracy: 0.7955\n",
            "Epoch 230/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7312 - accuracy: 0.7955\n",
            "Epoch 231/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.8030\n",
            "Epoch 232/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7284 - accuracy: 0.7955\n",
            "Epoch 233/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7273 - accuracy: 0.8030\n",
            "Epoch 234/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7260 - accuracy: 0.7955\n",
            "Epoch 235/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7246 - accuracy: 0.7955\n",
            "Epoch 236/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7232 - accuracy: 0.8030\n",
            "Epoch 237/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.8030\n",
            "Epoch 238/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.7955\n",
            "Epoch 239/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7186 - accuracy: 0.7955\n",
            "Epoch 240/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7166 - accuracy: 0.7955\n",
            "Epoch 241/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.8030\n",
            "Epoch 242/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.8030\n",
            "Epoch 243/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7123 - accuracy: 0.8030\n",
            "Epoch 244/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7121 - accuracy: 0.8030\n",
            "Epoch 245/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7106 - accuracy: 0.8106\n",
            "Epoch 246/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7088 - accuracy: 0.8030\n",
            "Epoch 247/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7074 - accuracy: 0.8030\n",
            "Epoch 248/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7059 - accuracy: 0.8030\n",
            "Epoch 249/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.8106\n",
            "Epoch 250/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.8182\n",
            "Epoch 251/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7026 - accuracy: 0.8182\n",
            "Epoch 252/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.8182\n",
            "Epoch 253/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.8182\n",
            "Epoch 254/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.8182\n",
            "Epoch 255/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.8030\n",
            "Epoch 256/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6958 - accuracy: 0.8030\n",
            "Epoch 257/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6945 - accuracy: 0.8106\n",
            "Epoch 258/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.8182\n",
            "Epoch 259/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.8182\n",
            "Epoch 260/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.8182\n",
            "Epoch 261/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.8182\n",
            "Epoch 262/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.8182\n",
            "Epoch 263/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6874 - accuracy: 0.8106\n",
            "Epoch 264/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.8106\n",
            "Epoch 265/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.8106\n",
            "Epoch 266/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.8182\n",
            "Epoch 267/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.8182\n",
            "Epoch 268/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.8258\n",
            "Epoch 269/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.8258\n",
            "Epoch 270/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.8258\n",
            "Epoch 271/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6779 - accuracy: 0.8106\n",
            "Epoch 272/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6767 - accuracy: 0.8106\n",
            "Epoch 273/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6755 - accuracy: 0.8182\n",
            "Epoch 274/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.8182\n",
            "Epoch 275/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6726 - accuracy: 0.8182\n",
            "Epoch 276/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.8106\n",
            "Epoch 277/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6704 - accuracy: 0.8106\n",
            "Epoch 278/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.8106\n",
            "Epoch 279/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6678 - accuracy: 0.8106\n",
            "Epoch 280/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6667 - accuracy: 0.8106\n",
            "Epoch 281/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6652 - accuracy: 0.8106\n",
            "Epoch 282/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.8182\n",
            "Epoch 283/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.8182\n",
            "Epoch 284/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.8182\n",
            "Epoch 285/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6621 - accuracy: 0.8182\n",
            "Epoch 286/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.8182\n",
            "Epoch 287/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.8182\n",
            "Epoch 288/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6587 - accuracy: 0.8182\n",
            "Epoch 289/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6573 - accuracy: 0.8258\n",
            "Epoch 290/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6562 - accuracy: 0.8258\n",
            "Epoch 291/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6551 - accuracy: 0.8258\n",
            "Epoch 292/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6541 - accuracy: 0.8258\n",
            "Epoch 293/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.8258\n",
            "Epoch 294/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.6518 - accuracy: 0.8258\n",
            "Epoch 295/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.8182\n",
            "Epoch 296/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.8182\n",
            "Epoch 297/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.8182\n",
            "Epoch 298/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.8258\n",
            "Epoch 299/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.8333\n",
            "Epoch 300/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6453 - accuracy: 0.8333\n",
            "Epoch 301/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.8333\n",
            "Epoch 302/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.8333\n",
            "Epoch 303/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6421 - accuracy: 0.8333\n",
            "Epoch 304/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.8333\n",
            "Epoch 305/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.8258\n",
            "Epoch 306/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.8258\n",
            "Epoch 307/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.8258\n",
            "Epoch 308/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.8258\n",
            "Epoch 309/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.8333\n",
            "Epoch 310/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.8333\n",
            "Epoch 311/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.8333\n",
            "Epoch 312/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6327 - accuracy: 0.8258\n",
            "Epoch 313/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6317 - accuracy: 0.8333\n",
            "Epoch 314/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6314 - accuracy: 0.8182\n",
            "Epoch 315/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6300 - accuracy: 0.8258\n",
            "Epoch 316/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.8258\n",
            "Epoch 317/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6277 - accuracy: 0.8258\n",
            "Epoch 318/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6270 - accuracy: 0.8258\n",
            "Epoch 319/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.8258\n",
            "Epoch 320/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.8333\n",
            "Epoch 321/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.8333\n",
            "Epoch 322/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.8333\n",
            "Epoch 323/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.8333\n",
            "Epoch 324/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.8333\n",
            "Epoch 325/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.8409\n",
            "Epoch 326/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.8409\n",
            "Epoch 327/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.8409\n",
            "Epoch 328/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6167 - accuracy: 0.8409\n",
            "Epoch 329/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.8409\n",
            "Epoch 330/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.8409\n",
            "Epoch 331/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.8409\n",
            "Epoch 332/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6136 - accuracy: 0.8485\n",
            "Epoch 333/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6122 - accuracy: 0.8409\n",
            "Epoch 334/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.8409\n",
            "Epoch 335/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.8409\n",
            "Epoch 336/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6095 - accuracy: 0.8409\n",
            "Epoch 337/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.8333\n",
            "Epoch 338/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.8485\n",
            "Epoch 339/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.8485\n",
            "Epoch 340/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6065 - accuracy: 0.8485\n",
            "Epoch 341/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.8485\n",
            "Epoch 342/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.8409\n",
            "Epoch 343/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6033 - accuracy: 0.8409\n",
            "Epoch 344/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.8485\n",
            "Epoch 345/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.6015 - accuracy: 0.8561\n",
            "Epoch 346/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.8561\n",
            "Epoch 347/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5994 - accuracy: 0.8485\n",
            "Epoch 348/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.8485\n",
            "Epoch 349/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5979 - accuracy: 0.8333\n",
            "Epoch 350/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5976 - accuracy: 0.8333\n",
            "Epoch 351/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5967 - accuracy: 0.8258\n",
            "Epoch 352/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.8258\n",
            "Epoch 353/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5951 - accuracy: 0.8409\n",
            "Epoch 354/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.8485\n",
            "Epoch 355/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5932 - accuracy: 0.8485\n",
            "Epoch 356/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5924 - accuracy: 0.8485\n",
            "Epoch 357/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5915 - accuracy: 0.8485\n",
            "Epoch 358/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.8485\n",
            "Epoch 359/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.8485\n",
            "Epoch 360/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.8485\n",
            "Epoch 361/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.8409\n",
            "Epoch 362/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5872 - accuracy: 0.8561\n",
            "Epoch 363/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5863 - accuracy: 0.8485\n",
            "Epoch 364/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.8485\n",
            "Epoch 365/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5852 - accuracy: 0.8485\n",
            "Epoch 366/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5843 - accuracy: 0.8333\n",
            "Epoch 367/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.8409\n",
            "Epoch 368/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.8409\n",
            "Epoch 369/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.8409\n",
            "Epoch 370/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.8409\n",
            "Epoch 371/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5806 - accuracy: 0.8485\n",
            "Epoch 372/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5789 - accuracy: 0.8485\n",
            "Epoch 373/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5782 - accuracy: 0.8485\n",
            "Epoch 374/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5770 - accuracy: 0.8561\n",
            "Epoch 375/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.8636\n",
            "Epoch 376/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5757 - accuracy: 0.8636\n",
            "Epoch 377/400\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.5751 - accuracy: 0.8636\n",
            "Epoch 378/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5739 - accuracy: 0.8636\n",
            "Epoch 379/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5730 - accuracy: 0.8636\n",
            "Epoch 380/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8636\n",
            "Epoch 381/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5717 - accuracy: 0.8712\n",
            "Epoch 382/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.8712\n",
            "Epoch 383/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.8712\n",
            "Epoch 384/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5689 - accuracy: 0.8712\n",
            "Epoch 385/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5681 - accuracy: 0.8712\n",
            "Epoch 386/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.8712\n",
            "Epoch 387/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.8636\n",
            "Epoch 388/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.8561\n",
            "Epoch 389/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.8561\n",
            "Epoch 390/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.8561\n",
            "Epoch 391/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.8485\n",
            "Epoch 392/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.8485\n",
            "Epoch 393/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5625 - accuracy: 0.8561\n",
            "Epoch 394/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.8561\n",
            "Epoch 395/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.8409\n",
            "Epoch 396/400\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.8485\n",
            "Epoch 397/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.8561\n",
            "Epoch 398/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5588 - accuracy: 0.8636\n",
            "Epoch 399/400\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.8636\n",
            "Epoch 400/400\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5575 - accuracy: 0.8636\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4dac410d50>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_avg = []\n",
        "for i in range(X_test.shape[0]):\n",
        "    X_test_avg.append(sentence_to_avg(X_test[i]))\n",
        "\n",
        "X_test_avg = np.array(X_test_avg)\n",
        "model_v1.evaluate(X_test_avg, Y_test_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU2bJ3BcwW8_",
        "outputId": "2da81b01-4a54-44ad-852b-ca47265386ad"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6457 - accuracy: 0.8393\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6457489728927612, 0.8392857313156128]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_me = np.array([\"not sad\", \"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy and funny\"])\n",
        "Y_me = np.array([[2], [0], [0], [2], [1], [4], [3]])\n",
        "X_me_avg = []\n",
        "\n",
        "for x in X_me:\n",
        "    X_me_avg.append(sentence_to_avg(x))\n",
        "\n",
        "X_me_avg = np.array(X_me_avg)\n",
        "pred = model_v1.predict(X_me_avg)\n",
        "\n",
        "for i in range(X_me.shape[0]):\n",
        "    print(X_me[i], label_to_emoji(np.argmax(pred[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeX5y8x6yAqg",
        "outputId": "1daa3f77-940d-4de5-f68f-6eb28862c510"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 94ms/step\n",
            "not sad üòî\n",
            "i adore you ‚ù§Ô∏è\n",
            "i love you ‚ù§Ô∏è\n",
            "funny lol üòÇ\n",
            "lets play with a ball ‚öΩ\n",
            "food is ready üçΩÔ∏è\n",
            "not feeling happy and funny üòÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emojifier-V2: Using RNNs:\n",
        "Let's build an LSTM model that takes as input word sequences. This model will be able to take word ordering into account. Emojifier-V2 will continue to use pre-trained word embeddings to represent words, but will feed them into an LSTM, whose job it is to predict the most appropriate emoji. \\n\",\n",
        "Run the following cell to load the Keras packages.\n",
        "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/emojifier-v2.png?raw=1\\\" style=\"width:700px;height:400px;\\\"> <caption><center> **Figure 3**: Emojifier-V2. A 2-layer LSTM sequence classifier. </center></caption>\n"
      ],
      "metadata": {
        "id": "2igA-sA09R1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_sentence_to_embeddings(X):\n",
        "  emb_matrix = np.zeros((X.shape[0], #size of dataset\n",
        "                        10, # len of longest sentence\n",
        "                        50 # size of emmbedings vector\n",
        "                        ))\n",
        "  for i in range(X.shape[0]):\n",
        "      words = X[i].lower().split()\n",
        "      for j in range(len(words)):\n",
        "          emb_matrix[i,j,:] = words_to_vec[words[j]]\n",
        "  return emb_matrix"
      ],
      "metadata": {
        "id": "EaiX0udrQ5zI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/Alireza-Akhavan/rnn-notebooks/blob/master/images/embedding1.png?raw=1\\\" style=\"width:700px;height:250px;\\\">\n",
        "<caption> **Figure 4**: Embedding layer. This example shows the propagation of two examples through the embedding layer. Both have been zero-padded to a length of `max_len=5`. The final dimension of the representation is  `(2,max_len,50)` because the word embeddings we are using are 50 dimensional.</caption>"
      ],
      "metadata": {
        "id": "_aYrC8AQT8cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_me = np.array([\"funny lol\",\"lets play baseball\" , \"food is ready for you\"])\n",
        "print(convert_sentence_to_embeddings(x_me))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh7ttjPe1ra3",
        "outputId": "19fe7b80-3417-4aa3-f787-6d60ec5b60b7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[-0.014547 -0.20208  -0.75278  ... -0.13429   0.21133   1.5368  ]\n",
            "  [-0.54289   0.053743 -0.46978  ...  0.20745  -0.074958  0.080575]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.30423  -0.24405   1.0303   ... -0.43296  -0.096168  0.43463 ]\n",
            "  [-0.73571   0.19937  -0.89408  ... -0.075279 -0.44448   0.47437 ]\n",
            "  [-1.9327    1.0421   -0.78515  ...  0.55667  -0.70315   0.17157 ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]\n",
            "\n",
            " [[ 0.47222  -0.44545  -0.51833  ...  0.34932   0.33934   0.25499 ]\n",
            "  [ 0.6185    0.64254  -0.46552  ... -0.27557   0.30899   0.48497 ]\n",
            "  [ 0.36825  -0.20512   0.36656  ...  0.40331  -0.47358   0.54165 ]\n",
            "  ...\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]\n",
            "  [ 0.        0.        0.       ...  0.        0.        0.      ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_emb = convert_sentence_to_embeddings(X_train)\n",
        "X_train_emb.shape"
      ],
      "metadata": {
        "id": "rves-nSS4ttu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25e6386-ec96-419f-f680-52a18a82709a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(132, 10, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Emoji_Net_V2(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lstm_1 = LSTM(128, return_sequences=True)\n",
        "        self.dropout_1 = Dropout(0.5)\n",
        "        self.lstm_2 = LSTM(128)\n",
        "        self.dropout_2 = Dropout(0.5)\n",
        "        self.dense = Dense(5, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.lstm_1(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.lstm_2(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "djWiWbxv8lpv"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2 = Emoji_Net_V2()\n",
        "model_v2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model_v2.fit(X_train_emb, Y_train_oh, epochs = 50, batch_size = 16, shuffle = True)"
      ],
      "metadata": {
        "id": "tiIeRGTFPgLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2a6c4c-4f11-48a2-9b11-df13c4779d05"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 4s 25ms/step - loss: 1.5792 - accuracy: 0.2576\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 1.4790 - accuracy: 0.3409\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 1.3790 - accuracy: 0.3636\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.2060 - accuracy: 0.5303\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 1.0075 - accuracy: 0.6212\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.8349 - accuracy: 0.7121\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.6287 - accuracy: 0.7955\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.5610 - accuracy: 0.7955\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.4315 - accuracy: 0.8561\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.3637 - accuracy: 0.9091\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2780 - accuracy: 0.9318\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.2822 - accuracy: 0.9167\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.1937 - accuracy: 0.9394\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.2583 - accuracy: 0.9091\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.3465 - accuracy: 0.8788\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.2201 - accuracy: 0.9242\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.2825 - accuracy: 0.8939\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.3952 - accuracy: 0.8409\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.1853 - accuracy: 0.9318\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.1728 - accuracy: 0.9545\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.1751 - accuracy: 0.9318\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.1321 - accuracy: 0.9621\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0634 - accuracy: 0.9924\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0565 - accuracy: 0.9848\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0572 - accuracy: 0.9848\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0862 - accuracy: 0.9697\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0733 - accuracy: 0.9621\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0391 - accuracy: 0.9848\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0365 - accuracy: 0.9848\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0235 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 23ms/step - loss: 0.0161 - accuracy: 0.9924\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 24ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 0.0014 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d9cc59950>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2.save('/content/drive/MyDrive/glove/model_v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyECOTyLTsFt",
        "outputId": "decf4079-b604-4e92-b080-6eeb0686caa0"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_12_layer_call_fn, lstm_cell_12_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_13_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_emb = convert_sentence_to_embeddings(X_test)\n",
        "Y_test_oh = tf.keras.utils.to_categorical(Y_test, 5)\n",
        "model_v2.evaluate(X_test_emb ,Y_test_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQqPslkGUcZs",
        "outputId": "08c1d370-f30f-4e88-b3e4-b76efeacb74c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 10ms/step - loss: 0.7699 - accuracy: 0.8571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7699219584465027, 0.8571428656578064]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_me = np.array([\"not sad\", \"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\",\"not good\"])\n",
        "Y_me = np.array([[2], [0], [0], [2], [1], [4], [3]])\n",
        "X_me_emb = convert_sentence_to_embeddings(X_me)\n",
        "\n",
        "pred = model_v2.predict(X_me_emb)\n",
        "\n",
        "for i in range(X_me.shape[0]):\n",
        "    print(X_me[i], label_to_emoji(np.argmax(pred[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5djl1N5LWa05",
        "outputId": "5b1cd0f4-bc5b-466b-fb90-102717baf165"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "not sad üòî\n",
            "i adore you ‚ù§Ô∏è\n",
            "i love you ‚ù§Ô∏è\n",
            "funny lol üòÇ\n",
            "lets play with a ball ‚öΩ\n",
            "food is ready üçΩÔ∏è\n",
            "not feeling happy üòî\n",
            "not good üòî\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3"
      ],
      "metadata": {
        "id": "kE1ftaTvUEtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Emoji_Net_V3(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lstm_1 = LSTM(64, return_sequences=True)\n",
        "        self.dropout_1 = Dropout(0.5)\n",
        "        self.lstm_2 = LSTM(32)\n",
        "        self.dropout_2 = Dropout(0.5)\n",
        "        self.dense = Dense(5, activation='softmax')\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.lstm_1(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.lstm_2(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.dense(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RhZHOC3NWk7M"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v3 = Emoji_Net_V3()\n",
        "model_v3.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model_v3.fit(X_train_emb, Y_train_oh, epochs = 50, batch_size = 16, shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9XsugHcUR4N",
        "outputId": "b6c7db77-c5a7-4d8a-f1cb-39664feeaf1b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 4s 13ms/step - loss: 1.5675 - accuracy: 0.2576\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.5260 - accuracy: 0.3409\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 16ms/step - loss: 1.4642 - accuracy: 0.3485\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.3912 - accuracy: 0.4545\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.2507 - accuracy: 0.5909\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.2199 - accuracy: 0.5455\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1307 - accuracy: 0.5682\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0302 - accuracy: 0.6667\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.9433 - accuracy: 0.6364\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7989 - accuracy: 0.7500\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.7677 - accuracy: 0.7273\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7346 - accuracy: 0.7727\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.6650 - accuracy: 0.7576\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6855 - accuracy: 0.7955\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.5327 - accuracy: 0.8258\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.4996 - accuracy: 0.8333\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.5044 - accuracy: 0.8182\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.7145 - accuracy: 0.7955\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.5303 - accuracy: 0.8106\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3718 - accuracy: 0.9091\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 0.3459 - accuracy: 0.9242\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.3088 - accuracy: 0.9167\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2927 - accuracy: 0.9091\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.3027 - accuracy: 0.9242\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4464 - accuracy: 0.8561\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2958 - accuracy: 0.9091\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2577 - accuracy: 0.9394\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.2163 - accuracy: 0.9470\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1945 - accuracy: 0.9470\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1845 - accuracy: 0.9394\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1781 - accuracy: 0.9470\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1468 - accuracy: 0.9697\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0923 - accuracy: 0.9848\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1172 - accuracy: 0.9697\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.1052 - accuracy: 0.9848\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0888 - accuracy: 0.9848\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0936 - accuracy: 0.9773\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0989 - accuracy: 0.9773\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1125 - accuracy: 0.9848\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1006 - accuracy: 0.9773\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0695 - accuracy: 0.9924\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0705 - accuracy: 0.9848\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0609 - accuracy: 0.9924\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0715 - accuracy: 0.9848\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.0871 - accuracy: 0.9621\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4929 - accuracy: 0.8409\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.2443 - accuracy: 0.9091\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1486 - accuracy: 0.9621\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1080 - accuracy: 0.9697\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.0818 - accuracy: 0.9848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d878cc550>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_emb = convert_sentence_to_embeddings(X_test)\n",
        "Y_test_oh = tf.keras.utils.to_categorical(Y_test, 5)\n",
        "model_v3.evaluate(X_test_emb ,Y_test_oh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMCyEp5iYf-E",
        "outputId": "ac8306b7-b2da-4ea2-a671-4d7e885e7ee9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 9ms/step - loss: 0.7457 - accuracy: 0.8036\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7456966042518616, 0.8035714030265808]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_me = np.array([\"not sad\", \"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\",\"not good\"])\n",
        "Y_me = np.array([[2], [0], [0], [2], [1], [4], [3]])\n",
        "X_me_emb = convert_sentence_to_embeddings(X_me)\n",
        "\n",
        "pred = model_v3.predict(X_me_emb)\n",
        "\n",
        "for i in range(X_me.shape[0]):\n",
        "    print(X_me[i], label_to_emoji(np.argmax(pred[i])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG1qXf9oYn26",
        "outputId": "3280a3c1-be6a-4944-8827-451f75dde7a4"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d8604c8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 802ms/step\n",
            "not sad üòî\n",
            "i adore you ‚ù§Ô∏è\n",
            "i love you ‚ù§Ô∏è\n",
            "funny lol üòÇ\n",
            "lets play with a ball ‚öΩ\n",
            "food is ready üçΩÔ∏è\n",
            "not feeling happy üòî\n",
            "not good üòî\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PfzVCC7YWbUv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}